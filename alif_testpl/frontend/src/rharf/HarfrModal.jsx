/* eslint-disable react-hooks/exhaustive-deps */
// eslint-disable no-empty */
/* eslint-disable no-unused-vars */
import React, { useState, useEffect, useRef, useCallback } from "react";
import { X } from "lucide-react";
import * as SpeechSDK from "microsoft-cognitiveservices-speech-sdk";
import "./HarfrModal.css";

// Set `VITE_RHARF_DEBUG=1` (or `VITE_HARF_DEBUG=1`) to enable verbose logs.
const RHARF_DEBUG =
    (import.meta.env?.VITE_RHARF_DEBUG || "") === "1" ||
    (import.meta.env?.VITE_HARF_DEBUG || "") === "1";
const rharfLog = (...args) => {
    if (RHARF_DEBUG) console.log(...args);
};
const rharfWarn = (...args) => {
    if (RHARF_DEBUG) console.warn(...args);
};
const rharfDebug = (...args) => {
    if (RHARF_DEBUG) console.debug(...args);
};

const HarfrModal = ({ isOpen, onClose, card, externalTranscript, onAskStateChange, onTranscriptConsumed, onComplete }) => {
    const [modalState, setModalState] = useState('initial');
    const [aiResponse, setAiResponse] = useState('');
    const [childTranscript, setChildTranscript] = useState('');
    const [isPlaying, setIsPlaying] = useState(false);
    const [currentIndex, setCurrentIndex] = useState(-1);
    const [earnedStars, setEarnedStars] = useState(0);

    // Fast STT (Azure Speech SDK)
    const [isListening, setIsListening] = useState(false);
    const [sttError, setSttError] = useState('');

    const speechConfigRef = useRef(null);
    const recognizerRef = useRef(null);
    const speechInitInProgressRef = useRef(false);
    const speechInitPromiseRef = useRef(null);

    // Keep latest callbacks without re-triggering effects on identity changes
    const onAskStateChangeRef = useRef(null);
    const onTranscriptConsumedRef = useRef(null);

    // Prevent re-processing the same transcript
    const lastHandledTranscriptKeyRef = useRef(null);

    const audioQueueRef = useRef([]);
    const isProcessingQueueRef = useRef(false);
    const synthesizerRef = useRef(null);
    const audioContextRef = useRef(null);
    const audioSourceRef = useRef(null);
    const htmlAudioRef = useRef(null);
    const htmlAudioUrlRef = useRef(null);

    useEffect(() => {
        onAskStateChangeRef.current = onAskStateChange;
        onTranscriptConsumedRef.current = onTranscriptConsumed;
    }, [onAskStateChange, onTranscriptConsumed]);

    // --- API endpoints ---
    const SMARTKIDS_API_BASE = import.meta.env.VITE_API_URL
        ? `${import.meta.env.VITE_API_URL}/smartkids`
        : "/api/v1/smartkids";

    const SPEECH_TOKEN_ENDPOINT = `${SMARTKIDS_API_BASE}/speech-token`;

    const ensureSpeechConfig = useCallback(async () => {
        if (speechConfigRef.current) return true;

        if (speechInitPromiseRef.current) {
            try {
                await speechInitPromiseRef.current;
            } catch (_) {
                // ignore
            }
            return !!speechConfigRef.current;
        }

        speechInitInProgressRef.current = true;
        const initPromise = (async () => {
            const resp = await fetch(SPEECH_TOKEN_ENDPOINT);
            if (!resp.ok) throw new Error(`speech-token failed: ${resp.status}`);
            const data = await resp.json();
            const cfg = SpeechSDK.SpeechConfig.fromAuthorizationToken(data.token, data.region);
            cfg.speechRecognitionLanguage = 'ru-RU';
            cfg.speechSynthesisVoiceName = 'ru-RU-SvetlanaNeural';
            try {
                cfg.setSpeechSynthesisOutputFormat(
                    SpeechSDK.SpeechSynthesisOutputFormat.Audio16Khz128KBitRateMonoMp3
                );
            } catch (_) {}
            speechConfigRef.current = cfg;
        })();

        speechInitPromiseRef.current = initPromise;
        try {
            await initPromise;
            return true;
        } catch (e) {
            console.error('‚ùå [HarfrModal] Speech config init failed:', e);
            setSttError("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏.");
            return false;
        } finally {
            speechInitPromiseRef.current = null;
            speechInitInProgressRef.current = false;
        }
    }, [SPEECH_TOKEN_ENDPOINT]);

    const hardStopTts = useCallback(() => {
        // Stop WebAudio playback
        try {
            if (audioSourceRef.current) {
                try { audioSourceRef.current.onended = null; } catch (_) {}
                try { audioSourceRef.current.stop(0); } catch (_) {}
                try { audioSourceRef.current.disconnect(); } catch (_) {}
            }
        } catch (_) {}
        audioSourceRef.current = null;

        // Stop HTMLAudio playback
        try {
            const a = htmlAudioRef.current;
            if (a) {
                try { a.pause(); } catch (_) {}
                try { a.currentTime = 0; } catch (_) {}
                try { a.src = ''; } catch (_) {}
            }
        } catch (_) {}
        htmlAudioRef.current = null;
        try {
            if (htmlAudioUrlRef.current) {
                URL.revokeObjectURL(htmlAudioUrlRef.current);
            }
        } catch (_) {}
        htmlAudioUrlRef.current = null;

        const currentSynth = synthesizerRef.current;
        if (currentSynth) {
            try {
                if (typeof currentSynth.stopSpeakingAsync === 'function') {
                    currentSynth.stopSpeakingAsync(
                        () => {
                            try { currentSynth.close(); } catch (_) {}
                        },
                        () => {
                            try { currentSynth.close(); } catch (_) {}
                        }
                    );
                } else {
                    currentSynth.close();
                }
            } catch (_) {
                try { currentSynth.close(); } catch (_) {}
            }
            synthesizerRef.current = null;
        }
    }, []);

    const stopRecognizer = useCallback(() => {
        try {
            recognizerRef.current?.stopContinuousRecognitionAsync?.();
        } catch (_) {}
        try {
            recognizerRef.current?.close?.();
        } catch (_) {}
        recognizerRef.current = null;
        setIsListening(false);
    }, []);

    const startListeningOnce = useCallback(async () => {
        if (modalState !== 'asking') return;
        if (isListening) return;

        setSttError('');
        setChildTranscript('');
        lastHandledTranscriptKeyRef.current = null;

        const ok = await ensureSpeechConfig();
        if (!ok || !speechConfigRef.current) return;

        try {
            setIsListening(true);

            try { recognizerRef.current?.close?.(); } catch (_) {}
            recognizerRef.current = null;

            const audioConfig = SpeechSDK.AudioConfig.fromDefaultMicrophoneInput();
            const recognizer = new SpeechSDK.SpeechRecognizer(speechConfigRef.current, audioConfig);
            recognizerRef.current = recognizer;

            recognizer.recognizeOnceAsync(
                (result) => {
                    setIsListening(false);
                    try { recognizer.close(); } catch (_) {}
                    if (recognizerRef.current === recognizer) recognizerRef.current = null;

                    const text = (result?.text || '').trim();
                    if (result?.reason === SpeechSDK.ResultReason.RecognizedSpeech && text) {
                        setChildTranscript(text);
                        return;
                    }
                    if (result?.reason === SpeechSDK.ResultReason.NoMatch) {
                        setSttError("–†–µ—á—å –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.");
                        return;
                    }
                    setSttError("–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏.");
                },
                (err) => {
                    console.error('‚ùå [HarfrModal] STT recognizeOnceAsync error:', err);
                    setIsListening(false);
                    try { recognizer.close(); } catch (_) {}
                    if (recognizerRef.current === recognizer) recognizerRef.current = null;
                    setSttError("–û—à–∏–±–∫–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ –∏–ª–∏ STT.");
                }
            );
        } catch (e) {
            console.error('‚ùå [HarfrModal] startListeningOnce failed:', e);
            setIsListening(false);
            setSttError("–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –º–∏–∫—Ä–æ—Ñ–æ–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è.");
        }
    }, [ensureSpeechConfig, isListening, modalState]);

    // –§—É–Ω–∫—Ü–∏—è –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ —Ä—É—Å—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è TTS
    function normalizeRussianForTTS(text) {
        try {
            if (!text) return '';
            
            // –ó–∞–º–µ–Ω—è–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –∏ –¥–µ–ª–∞–µ–º —Ç–µ–∫—Å—Ç —á–∏—Ç–∞–µ–º—ã–º
            let normalized = String(text)
             
            
            return normalized;
        } catch {
            return '';
        }
    }

    // –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø—Ä–æ–∏–∑–Ω–æ—à–µ–Ω–∏—è –±—É–∫–≤—ã
    function getLetterPronunciation(letter) {
        const l = (letter || '').toLowerCase();
        const map = {
            '–∞': '–∞', '–±': '–±—ç', '–≤': '–≤—ç', '–≥': '–≥—ç', '–¥': '–¥—ç',
            '–µ': '–π–µ', '—ë': '–π–æ', '–∂': '–∂—ç', '–∑': '–∑—ç', '–∏': '–∏',
            '–π': '–∏ –∫—Ä–∞—Ç–∫–æ–µ', '–∫': '–∫–∞', '–ª': '—ç–ª—å', '–º': '—ç–º', '–Ω': '—ç–Ω',
            '–æ': '–æ', '–ø': '–ø—ç', '—Ä': '—ç—Ä', '—Å': '—ç—Å', '—Ç': '—Ç—ç',
            '—É': '—É', '—Ñ': '—ç—Ñ', '—Ö': '—Ö–∞', '—Ü': '—Ü—ç', '—á': '—á–µ',
            '—à': '—à–∞', '—â': '—â–∞', '—ä': '—Ç–≤—ë—Ä–¥—ã–π –∑–Ω–∞–∫', '—ã': '—ã',
            '—å': '–º—è–≥–∫–∏–π –∑–Ω–∞–∫', '—ç': '—ç', '—é': '—é', '—è': '—è'
        };
        return map[l] || letter;
    }

    // –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –≤–æ–ø—Ä–æ—Å–∞
    function getQuestionText(letter) {
        const l = (letter || '').toLowerCase();
        const spoken = getLetterPronunciation(l);
        // –î–ª—è —ä, —å, —ã ‚Äî –æ—Å–æ–±–∞—è —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞
        if (['—ä', '—å', '—ã'].includes(l)) {
            return `–ù–∞–∑–æ–≤–∏ —Å–ª–æ–≤–æ, –≤ –∫–æ—Ç–æ—Ä–æ–º —É—á–∞—Å—Ç–≤—É–µ—Ç ${spoken}.`;
        }
        // –í –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Å–ª—É—á–∞—è—Ö ‚Äî –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –Ω–∞ –±—É–∫–≤—É
        return `–ù–∞–∑–æ–≤–∏ —Å–ª–æ–≤–æ, –∫–æ—Ç–æ—Ä–æ–µ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –Ω–∞ –±—É–∫–≤—É ${spoken}.`;
    }

    // –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏, –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –ª–∏ —Å–ª–æ–≤–æ —Å –Ω—É–∂–Ω–æ–π –±—É–∫–≤—ã
    function checkRussianWord(word, targetLetter) {
        if (!word || !targetLetter) return false;
        
        const firstChar = word[0].toLowerCase();
        const target = targetLetter.toLowerCase();
        
        // –û—Å–æ–±—ã–µ —Å–ª—É—á–∞–∏ –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞
        if (target === '–µ' && ['–µ', '—ë'].includes(firstChar)) return true;
        if (target === '—ë' && ['–µ', '—ë'].includes(firstChar)) return true;
        if (target === '–∏' && ['–∏', '–π'].includes(firstChar)) return true;
        // –î–ª—è —ä, —å, —ã —Ç—Ä–µ–±—É–µ—Ç—Å—è —É—á–∞—Å—Ç–∏–µ –±—É–∫–≤—ã –≤ —Å–ª–æ–≤–µ (–Ω–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –≤ –Ω–∞—á–∞–ª–µ)
        if (['—ä', '—å', '—ã'].includes(target)) {
            return word.toLowerCase().includes(target);
        }
        return firstChar === target;
    }

    // –î–µ—Ç–µ–∫—Ü–∏—è —Ç–∏–ø–∞ –∞—É–¥–∏–æ
    const processAudioQueue = useCallback(async () => {
        rharfDebug('üîÑ [HarfrModal] processAudioQueue', {
            queueLength: audioQueueRef.current.length,
            isProcessing: isProcessingQueueRef.current,
        });

        if (isProcessingQueueRef.current || audioQueueRef.current.length === 0) {
            return;
        }
        isProcessingQueueRef.current = true;
        setIsPlaying(true);

        let { text, onStart, onEnd } = audioQueueRef.current.shift();
        text = normalizeRussianForTTS(text);

        try {
            if (onStart) onStart();

            const ok = await ensureSpeechConfig();
            if (!ok || !speechConfigRef.current) throw new Error('Speech config not initialized');

            hardStopTts();

            rharfLog('üì§ [HarfrModal] Azure Speech SDK TTS:', text);

            const pullStream = SpeechSDK.AudioOutputStream.createPullStream();
            const sdkAudioConfig = SpeechSDK.AudioConfig.fromStreamOutput(pullStream);
            const synthesizer = new SpeechSDK.SpeechSynthesizer(speechConfigRef.current, sdkAudioConfig);
            synthesizerRef.current = synthesizer;

            const audioArrayBuffer = await new Promise((resolve, reject) => {
                synthesizer.speakTextAsync(
                    text,
                    (result) => {
                        try { synthesizer.close(); } catch (_) {}
                        if (synthesizerRef.current === synthesizer) synthesizerRef.current = null;

                        const data = result?.audioData;
                        if (!data) {
                            reject(new Error('Empty audioData'));
                            return;
                        }
                        if (data instanceof ArrayBuffer) {
                            resolve(data.slice(0));
                            return;
                        }
                        if (data?.buffer instanceof ArrayBuffer) {
                            resolve(data.buffer.slice(0));
                            return;
                        }
                        reject(new Error('Unknown audioData type'));
                    },
                    (err) => {
                        try { synthesizer.close(); } catch (_) {}
                        if (synthesizerRef.current === synthesizer) synthesizerRef.current = null;
                        reject(err || new Error('TTS failed'));
                    }
                );
            });

            if (!audioContextRef.current || audioContextRef.current.state === 'closed') {
                audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)();
            }
            if (audioContextRef.current.state === 'suspended') {
                try { await audioContextRef.current.resume(); } catch (_) {}
            }

            try {
                const decoded = await audioContextRef.current.decodeAudioData(audioArrayBuffer.slice(0));
                const src = audioContextRef.current.createBufferSource();
                src.buffer = decoded;
                src.connect(audioContextRef.current.destination);
                audioSourceRef.current = src;

                src.onended = () => {
                    if (audioSourceRef.current === src) audioSourceRef.current = null;
                    try { if (onEnd) onEnd(); } catch (_) {}
                    isProcessingQueueRef.current = false;
                    setIsPlaying(false);
                    setTimeout(() => processAudioQueue(), 200);
                };
                src.start(0);
                return;
            } catch (decodeErr) {
                rharfDebug('[HarfrModal] WebAudio decode failed, fallback to HTMLAudio', decodeErr);
            }

            const blob = new Blob([audioArrayBuffer], { type: 'audio/mpeg' });
            const url = URL.createObjectURL(blob);
            htmlAudioUrlRef.current = url;

            const audio = new Audio();
            htmlAudioRef.current = audio;
            audio.preload = 'auto';
            audio.src = url;
            audio.onended = () => {
                try { URL.revokeObjectURL(url); } catch (_) {}
                if (htmlAudioUrlRef.current === url) htmlAudioUrlRef.current = null;
                if (htmlAudioRef.current === audio) htmlAudioRef.current = null;
                try { if (onEnd) onEnd(); } catch (_) {}
                isProcessingQueueRef.current = false;
                setIsPlaying(false);
                setTimeout(() => processAudioQueue(), 200);
            };
            audio.onerror = () => {
                try { URL.revokeObjectURL(url); } catch (_) {}
                if (htmlAudioUrlRef.current === url) htmlAudioUrlRef.current = null;
                if (htmlAudioRef.current === audio) htmlAudioRef.current = null;
                isProcessingQueueRef.current = false;
                setIsPlaying(false);
                setTimeout(() => processAudioQueue(), 200);
            };

            try {
                await audio.play();
            } catch (playErr) {
                console.error('‚ùå [HarfrModal] HTMLAudio play blocked/failed:', playErr);
                try { URL.revokeObjectURL(url); } catch (_) {}
                if (htmlAudioUrlRef.current === url) htmlAudioUrlRef.current = null;
                if (htmlAudioRef.current === audio) htmlAudioRef.current = null;
                isProcessingQueueRef.current = false;
                setIsPlaying(false);
                setTimeout(() => processAudioQueue(), 200);
            }
        } catch (error) {
            console.error('‚ùå [HarfrModal] TTS error:', error?.message || error);

            try {
                if (onStart) onStart();
                if (onEnd) onEnd();
            } catch (_) {}

            isProcessingQueueRef.current = false;
            setIsPlaying(false);
            setTimeout(() => processAudioQueue(), 300);
        }
    }, [ensureSpeechConfig, hardStopTts]);

    const speakText = useCallback((text, onStart, onEnd) => {
        audioQueueRef.current.push({ 
            text: text, 
            onStart, 
            onEnd 
        });
        
        if (!isProcessingQueueRef.current) {
            processAudioQueue();
        }
    }, [processAudioQueue]);

    // –û—Å–Ω–æ–≤–Ω–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —á—Ç–µ–Ω–∏—è
    const startReadingSequence = useCallback(() => {
        if (!card) return;

        rharfDebug('üé¨ [HarfrModal] Starting reading sequence for:', card?.label);
        setModalState('reading');
        audioQueueRef.current = [];
        isProcessingQueueRef.current = false;
        
        const parts = (card.label || '').split(' ');
        const smallLetter = (parts.length > 1 ? parts[1] : parts[0]);
        const letterPronunciation = getLetterPronunciation(smallLetter);
        
        // –ü—Ä–æ–∏–∑–Ω–æ—Å–∏–º –±—É–∫–≤—É
        speakText(
            `${letterPronunciation}`, 
            () => setCurrentIndex(-1)
        );

        if (!card.examples || card.examples.length === 0) {
            rharfWarn('‚ö†Ô∏è [HarfrModal] No examples in card');
            return;
        }

        // –ü—Ä–æ–∏–∑–Ω–æ—Å–∏–º –ø—Ä–∏–º–µ—Ä—ã
        card.examples.forEach((example, index) => {
            rharfDebug(`üéµ [HarfrModal] Adding example ${index + 1}:`, example);
            speakText(
                example,
                () => {
                    rharfDebug(`‚ñ∂Ô∏è [HarfrModal] Playing example ${index + 1}:`, example);
                    setCurrentIndex(index);
                },
                index === card.examples.length - 1 ? () => {
                    rharfDebug('‚úÖ [HarfrModal] All examples completed, asking question');
                    setCurrentIndex(-1);
                    const question = getQuestionText(smallLetter);
                    rharfDebug('‚ùì [HarfrModal] Question:', question);
                    speakText(question, null, () => {
                        rharfDebug('üé§ [HarfrModal] Ready for answer');
                        setIsPlaying(false);
                        setModalState('asking');
                        try { onAskStateChangeRef.current?.(false); } catch (_) {}
                    });
                } : null
            );
        });

        rharfDebug('üìã [HarfrModal] Total items in queue:', audioQueueRef.current.length);
    }, [card, speakText]);

    // –≠—Ñ—Ñ–µ–∫—Ç—ã
    useEffect(() => {
        if (isOpen && card) {
            // Reset states first
            setModalState('initial');
            setAiResponse('');
            setChildTranscript('');
            setIsPlaying(false);
            setCurrentIndex(-1);
            setEarnedStars(0);
            audioQueueRef.current = [];
            isProcessingQueueRef.current = false;
            setSttError('');
            setIsListening(false);
            lastHandledTranscriptKeyRef.current = null;

            // Warm up speech config
            ensureSpeechConfig();

            const timer = setTimeout(() => {
                startReadingSequence();
            }, 100);

            return () => clearTimeout(timer);
        }
        
        if (!isOpen) {
            audioQueueRef.current = [];
            isProcessingQueueRef.current = false;
            setModalState('initial');
            setAiResponse('');
            setChildTranscript('');
            setIsPlaying(false);
            setCurrentIndex(-1);
            setEarnedStars(0);
            stopRecognizer();
            hardStopTts();
            try { onAskStateChangeRef.current?.(false); } catch (_) {}
            lastHandledTranscriptKeyRef.current = null;
        }
    }, [isOpen, card?.label, ensureSpeechConfig, startReadingSequence, stopRecognizer, hardStopTts]);

    // Unmount cleanup
    useEffect(() => {
        return () => {
            stopRecognizer();
            hardStopTts();
        };
    }, [stopRecognizer, hardStopTts]);

    // –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
    useEffect(() => {
        const incoming = childTranscript || externalTranscript;
        if (modalState === 'asking' && incoming) {
            const transcript = incoming.trim();
            const key = `${card?.label || ''}::${transcript}`;
            if (lastHandledTranscriptKeyRef.current === key) {
                return;
            }
            lastHandledTranscriptKeyRef.current = key;

            const partsForTarget = (card?.label || '').split(' ');
            const targetLetter = (partsForTarget.length > 1 ? partsForTarget[1] : partsForTarget[0]).toLowerCase();
            
            if (!targetLetter || !transcript) return;

            const words = transcript
              .split(/[\s,.;:!?]+/)
              .map(w => w.trim())
              .filter(Boolean);

            let responseText = '';
            const letterPronunciation = getLetterPronunciation(targetLetter);
            let correctCount = 0;
            let totalWords = words.length;

            const matches = words.filter(w => checkRussianWord(w, targetLetter));
            const nonMatches = words.filter(w => !checkRussianWord(w, targetLetter));
            correctCount = matches.length;
            
            if (matches.length > 0) {
                responseText += `–ú–æ–ª–æ–¥–µ—Ü! –°–ª–æ–≤–∞ "${matches.join(', ')}" –Ω–∞—á–∏–Ω–∞—é—Ç—Å—è –Ω–∞ –±—É–∫–≤—É ${letterPronunciation}`;
            }
            
            if (nonMatches.length > 0) {
                const prefix = matches.length > 0 ? ". –ê —Å–ª–æ–≤–∞ " : "";
                responseText += `${prefix}"${nonMatches.join(', ')}" –Ω–∞—á–∏–Ω–∞—é—Ç—Å—è –Ω–∞ –¥—Ä—É–≥–∏–µ –±—É–∫–≤—ã`;
            }

            // Yulduzcha hisobini aniqlash
            let stars = 1; // Default: 1 yulduzcha
            if (totalWords > 0) {
                if (correctCount === totalWords) {
                    stars = 3; // Barcha to'g'ri
                } else if (correctCount > 0) {
                    stars = 2; // Qisman to'g'ri
                }
            }
            setEarnedStars(stars);
            
            // Save stars to localStorage
            if (stars > 0) {
                try {
                    const currentTotal = parseInt(localStorage.getItem('harfrModal_totalStars') || '0');
                    localStorage.setItem('harfrModal_totalStars', String(currentTotal + stars));
                    
                    const history = JSON.parse(localStorage.getItem('harfrModal_starsHistory') || '[]');
                    history.push({
                        // IMPORTANT: store by card.label so Harfr.jsx can display stars per card
                        letter: card?.label || 'unknown',
                        stars: stars,
                        timestamp: new Date().toISOString()
                    });
                    localStorage.setItem('harfrModal_starsHistory', JSON.stringify(history));
                } catch (error) {
                    console.error('Error saving stars to localStorage:', error);
                }
            }

            if (!responseText) {
                if (['—ä', '—å', '—ã'].includes(targetLetter)) {
                    responseText = `–•–æ—Ä–æ—à–∞—è –ø–æ–ø—ã—Ç–∫–∞! –ü–æ–ø—Ä–æ–±—É–π –Ω–∞–∑–≤–∞—Ç—å —Å–ª–æ–≤–æ, –≤ –∫–æ—Ç–æ—Ä–æ–º —É—á–∞—Å—Ç–≤—É–µ—Ç ${targetLetter}`;
                } else {
                    responseText = `–•–æ—Ä–æ—à–∞—è –ø–æ–ø—ã—Ç–∫–∞! –ü–æ–ø—Ä–æ–±—É–π –Ω–∞–∑–≤–∞—Ç—å —Å–ª–æ–≤–æ, –∫–æ—Ç–æ—Ä–æ–µ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –Ω–∞ –±—É–∫–≤—É ${letterPronunciation}`;
                }
            }

            setChildTranscript(transcript);
            setAiResponse(responseText);
            
            speakText(responseText, null, () => {
                setModalState('asking');
                try { onAskStateChangeRef.current?.(false); } catch (_) {}
                try { onTranscriptConsumedRef.current?.(); } catch (_) {}
            });
        }
    }, [childTranscript, externalTranscript, modalState, card, speakText]);

    if (!isOpen || !card) return null;

    return (
        <div className="harf-modal" onClick={onClose}>
            <div className="harf-modal-content" onClick={(e) => e.stopPropagation()}>
                <button className="harf-modal-close" onClick={onClose}>
                    <X size={24} />
                </button>
                
                <div className="harf-modal-letters">
                    {(() => {
                        const p = (card.label || '').split(' ');
                        const big = p.length > 1 ? p[0] : p[0];
                        const small = p.length > 1 ? p[1] : p[0];
                        return (
                            <>
                                <div className="big-letter">{big}</div>
                                <div className="small-letter">{small}</div>
                            </>
                        );
                    })()}
                </div>

                <div className="audio-controls">
                    <button 
                        className="reread-button" 
                        onClick={startReadingSequence} 
                        disabled={isPlaying}
                    >
                        üîÑ –ü–æ–≤—Ç–æ—Ä–∏—Ç—å
                    </button>
                </div>

                <div className="harf-examples-container">
                    {[0, 1].map(row => (
                        <div className="harf-examples-row" key={row}>
                            {card.examples.slice(row * 2, row * 2 + 2).map((example, idx) => {
                                const index = row * 2 + idx;
                                return (
                                    <div 
                                        key={index}
                                        className={`example-card ${currentIndex === index && isPlaying ? 'active' : ''}`}
                                        onClick={() => { if (!isPlaying) speakText(example); }}
                                    >
                                        <div className="example-emoji">{card.exampleImages[index]}</div>
                                        <div className="example-text">{example}</div>
                                        {currentIndex === index && isPlaying && <div className="playing-indicator">üîä</div>}
                                    </div>
                                );
                            })}
                        </div>
                    ))}
                </div>

                <div className="ai-interaction-section">
                    <h4 className="ai-title">–í–æ–ø—Ä–æ—Å/–û—Ç–≤–µ—Ç</h4>
                    <div className="ai-response-box">
                        {modalState === 'asking' && (() => {
                            const p = (card.label || '').split(' ');
                            const s = p.length > 1 ? p[1] : p[0];
                            const q = getQuestionText(s);
                            return <p>{q}</p>;
                        })()}
                    </div>
                    
                    {childTranscript && (
                        <div className="child-transcript-box">
                            <p><b>–†–µ–±—ë–Ω–æ–∫:</b> <i>{childTranscript}</i></p>
                        </div>
                    )}
                    
                    {aiResponse && (
                        <div className="ai-response-box">
                            <p>{aiResponse}</p>
                            {earnedStars > 0 && (
                                <div className="stars-earned" style={{ marginTop: '10px', fontSize: '24px' }}>
                                    {[...Array(earnedStars)].map((_, i) => <span key={i}>‚≠ê</span>)}
                                </div>
                            )}
                        </div>
                    )}
                    
                    <div className="assistant-inline">
                        <button
                            type="button"
                            onClick={startListeningOnce}
                            disabled={modalState !== 'asking' || isListening}
                            className="reread-button"
                            style={{ minWidth: 0 }}
                            aria-label={isListening ? "–°–ª—É—à–∞—é" : "–ú–∏–∫—Ä–æ—Ñ–æ–Ω"}
                            title={isListening ? "–°–ª—É—à–∞—é" : "–ú–∏–∫—Ä–æ—Ñ–æ–Ω"}
                        >
                            {isListening ? 'üéôÔ∏è –°–ª—É—à–∞—é...' : 'üé§ –ì–æ–≤–æ—Ä–∏—Ç—å'}
                        </button>

                        {sttError ? (
                            <span className="assistant-error">{sttError}</span>
                        ) : null}
                    </div>
                    
                    {modalState === 'asking' && (
                        <div className="complete-row">
                            <button 
                                className="complete-button" 
                                onClick={() => { 
                                    try { 
                                        onComplete && onComplete(); 
                                    } catch {}; 
                                }}
                            >
                                ‚úîÔ∏è –ì–æ—Ç–æ–≤–æ
                            </button>
                        </div>
                    )}
                </div>
            </div>
        </div>
    );
};

export default HarfrModal;